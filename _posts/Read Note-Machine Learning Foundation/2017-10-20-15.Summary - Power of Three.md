---
layout: post
title: 15.Summary - Power of Three
category: Read-Note22
keywords: Reading, Machine Learning Foundation
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>


# Summary - Power of Three
<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->

- [Summary - Power of Three](#summary-power-of-three)
	- [1. Three Related Fields](#1-three-related-fields)
		- [1) Machine Learning V.S. Data Mining](#1-machine-learning-vs-data-mining)
		- [2) Machine Learning V.S. Artificial Intelligence](#2-machine-learning-vs-artificial-intelligence)
		- [3) Machine Learning V.S. Statistic](#3-machine-learning-vs-statistic)
	- [2. Three Theoretical Bounds](#2-three-theoretical-bounds)
	- [3. Three Linear Models](#3-three-linear-models)
	- [4. Three Key Tools](#4-three-key-tools)
	- [5. Three Learning Principles](#5-three-learning-principles)
	- [6. Three Future Directions](#6-three-future-directions)
- [Summary](#summary)
- [Reference](#reference)

<!-- /TOC -->

> 总结整个课程，发现很多内容数量刚好都是三。

## 1. Three Related Fields
对比三个相关的领域:
- Data Mining
- Artificial Intelligence
- Statistic


机器学习是学习问题，而不是优化问题，也就是说，机器学习不仅要求数据在训练集上求得一个较小的误差，而且在测试集上也要表现的好（因为模型最终是要部署在实际的场景中，数据也是没有训练过的），即机器学习既要低误差，又要很好地泛化能力，以保证实际的误差与训练误差相差不大。

### 1) Machine Learning V.S. Data Mining
机器学习与数据挖掘都叫知识发现（KDD Knowledge Discovery in Dataset）。
- 两者是一致的：能够找出的有用信息就是我们要求得的近似目标函数的假设。
- 两者是互助的：ML需要大数据的支持才能保持能“学到东西”。
- 数据挖掘更关注于从大量的数据中的计算问题。
总的来时，两者密不可分。

### 2) Machine Learning V.S. Artificial Intelligence
AI是通过特定的方法让机器能做出Intelligent的行为，ML属于AI的一个分支，是AI实现的一种方式

### 3) Machine Learning V.S. Statistic
统计是通过对已知数据的处理，从而推断出未知的事件的属性
所以统计学是实现ML的一种方法，统计学里面有许多实用的工具可以用于证明ML。


------------------------------------------
</br>
</br>


## 2. Three Theoretical Bounds
三个理论基础是保证了机器在满足数据量足够大，且有合适的算法的情况下，可以实现机器学习。
三个理论基础如下：
- Hoeffding Inequity（单一假设确认时使用）
- Multi-Bin Hoffding Inequity（有限多个假设验证时使用）
- VC Bound（无限多个假设训练时使用）

------------------------------------------
</br>
</br>


## 3. Three Linear Models
前面我们讨论的Linear Model 有:
- Linear Classification (PLA, Pocket)
- Linear Regression
- Logistic Regression

具体如图一所示

![Three Linear Models](https://raw.githubusercontent.com/JasonDean-1/MarkdownPhoto/d3c8fe5c2f9329f339cd5577a6da9be9c5afacdb/MachineLearning/Machine%20Learning%20Foundation%20--%20Hsuan-Tien%20Lin%20in%20NTU/chapter15-1%20Three%20Linear%20Models.png)
<center> 图一 Three Linear Models <sup>[1]</sup></center>
</br>

------------------------------------------
</br>
</br>

## 4. Three Key Tools
3个重要的工具如：
- Feature Transform - 遇到太复杂的模型，可以映射到线性的空间去做处理 (Nonlinear Transform)
- Regularization - 通过加入惩罚项，来降低模型的复杂度 (Ridge Regression)
- Validation - 通过拿出部分数据来作为验证集，用于评估模型，方法（Leave-One-Out Cross Validation, V-Fold Cross Validation

具体如图二所示

![Three Key Tools](https://raw.githubusercontent.com/JasonDean-1/MarkdownPhoto/895d348fc9bd1a9a08b11926ca181de1fa8cfcde/MachineLearning/Machine%20Learning%20Foundation%20--%20Hsuan-Tien%20Lin%20in%20NTU/chapter15-2%20Three%20Key%20Tools.png)
<center> 图二 Three Key Tools <sup>[1]</sup></center>
</br>

------------------------------------------
</br>
</br>

## 5. Three Learning Principles
- Occam’s Razor - 越简单而有效的模型越好！
- Sampling Bias的坏处 - 我们在训练时要保证数据的来源，最好是相互独立的
- Data Snooping坏处 - 尽量先选择模型，然后在去查看数据，然后在训练的过程要保持怀疑的态度


------------------------------------------
</br>
</br>

## 6. Three Future Directions
未来机器学习的方向也分为三种：
- More Transform - 转换也能使得模型更加简单
- More Regularization - 尽可能降低模型的复杂度
- Less Label - 更少的Feature，那么模型将更好

具体如图三所示

![Three Key Tools](https://raw.githubusercontent.com/JasonDean-1/MarkdownPhoto/9cf0f34b806ade1492c029bfefc6ccbaf4dfc42c/MachineLearning/Machine%20Learning%20Foundation%20--%20Hsuan-Tien%20Lin%20in%20NTU/chapter15-3%20Three%20Future%20Directions.png)
<center> 图三 Three Future Directions <sup>[1]</sup></center>
</br>



------------------------------------------
</br>
</br>


#Summary
1. 总结整个课程

至此，Machine Learning Foundation （机器学习基石）的笔记总结完毕，有部分内容后续补充

</br></br>
----------------------------------

# Reference
[1] 机器学习基石(台湾大学-林轩田)\16\16 - 4 - Power of Three (08-49)
