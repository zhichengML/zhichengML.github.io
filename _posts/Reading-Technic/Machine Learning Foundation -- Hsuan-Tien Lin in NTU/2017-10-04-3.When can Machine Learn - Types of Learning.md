---
layout: post
title: 3.When can Machine Learn? - Types of Learning
category: Read-Note4
keywords: Reading, Machine Learning Foundation
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>


formula1: $$n==x$$
formula2: $$n!=x$$
formula3: $n==x$safaf
formula4: $n!=x$safs


formula1: $$n==x$$
formula2: $$n!=x$$
formula3: $n==x$safaf
formula4: $n!=x$safs
formula1: $$n==x$$
formula2: $$n!=x$$
formula3: $n==x$safaf
formula4: $n!=x$safs
formula1: $$n==x$$
formula2: $$n!=x$$
formula3: $n==x$safaf
formula4: $n!=x$safs


# When can Machine Learn? - Types of Learning
----------------------------------
<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->

- [When can Machine Learn? - Types of Learning](#when-can-machine-learn-types-of-learning)
	- [1. Learning with Different Output Space](#1-learning-with-different-output-space)
		- [1) Binary Classification](#1-binary-classification)
		- [2) Multiclass Classification](#2-multiclass-classification)
		- [3) Regression](#3-regression)
		- [4) Structured Learning （不熟悉）](#4-structured-learning-不熟悉)
	- [2. Learning with Different Data Label](#2-learning-with-different-data-label)
		- [1) Supervised Learning](#1-supervised-learning)
		- [2) Semi-supervised Learning](#2-semi-supervised-learning)
		- [3) Unsupervised Learning](#3-unsupervised-learning)
		- [4) Reinforcement Learning](#4-reinforcement-learning)
	- [3. Learning with Different Protocol](#3-learning-with-different-protocol)
		- [1) Batch](#1-batch)
		- [2) Online](#2-online)
		- [3) Active](#3-active)
	- [4. Learning with Different Input Space](#4-learning-with-different-input-space)
		- [1) Concrete Features](#1-concrete-features)
		- [2) Raw Features](#2-raw-features)
		- [3) Abstract Features](#3-abstract-features)

<!-- /TOC -->
</br></br>
----------------------------------

## 1. Learning with Different Output Space
介绍类型的输出空间：二值输出（二元分类），多值输出（多元分类），实数输出（回归），结构输出

### 1) Binary Classification
前两章中提到的银行发信用卡问题就是一个典型的二元分类问题，其输出空间只包含两个标记+1和-1，分别对应着发卡与不发卡。
用符号可以表示为：
$$
g(x) ∈ \{value_1, value_2\}
\tag{$1$}
$$

常用的算法有：
> 以后补充

### 2) Multiclass Classification
有二元分类，就不难想到多元分类的问题，该类问题输出标签不止两种，而是{1,2,…,K}。这在人们的生活中非常常见，比如给病人症状的分类，购买物品的种类等等，其主要的应用场景就是模式识别。
用符号可以表示为：
$$
g(x) ∈ \{value_1, value_2, ..., value_n\}
\tag{$2$}
$$

常用的算法有：
> 以后补充

### 3) Regression
当输出的空间为实数的时候，就属于回归问题，这种输出与二元，多元分类的区别在于，我们无法提前打好标签到输出结果中。应用场景为：病人患病几率，给客户发信用卡的几率等。统计学中对回归问题有很多处理方法，以及评估的方法。
用符号可以表示为：
$$
g(x) ∈ [ a, b ]
\tag{$$}
$$

常用的算法有：
> 以后补充

### 4) Structured Learning （不熟悉）
结构化的学习，就是说输出的结果可能是一串特定的结构的数据，比如说语义识别中的语意结构。

常用的算法有：
> 以后补充



--------------------------------

</br></br>


## 2. Learning with Different Data Label
不同的数据标记: 标记了输入和输出（监督学习），标记部分数据的输入和输出（半监督学习），什么都不标记（无监督学习），训练模型根据后天的反馈进行调整（增强学习）

常用的算法有：
> 以后补充

### 1) Supervised Learning
知道数据输入的同时还知道数据的标记。就相当于告诉你题目的同时还告诉你答案，让你在这种环境下学习，称之为监督学习（supervised learning）或者叫有师学习（learning with a teacher），之前讨论的一些算法都是这类问题。

常用的算法有：
> 以后补充

### 2) Semi-supervised Learning
半监督学习，它通过少量有标记的训练点和大量无标记的训练点达到学习的目的。这种类型的例子也有很多，比如图像的识别，很多情况下我们不可能把每张图片都做上标记（因为做这种标记需要耗费大量的人力物力，是一种昂贵的行为），此时，使用半监督学习是一种不错的选择。

常用的算法有：
> 以后补充

### 3) Unsupervised Learning
这是一种没有标示（就是没有输出y）的问题，就是不告诉你题目的正确答案让你自己去做题。

常用的算法有：
> 以后补充

### 4) Reinforcement Learning
前面三种学习方式是机器学习中最传统的三种方式，除此之外，通过对一个行为作出奖励或者惩罚，以此获得的输出，进而进行学习，这种学习方式称之为强化学习。

常用的算法有：
> 以后补充



--------------------------------
</br></br>

## 3. Learning with Different Protocol
通过不同的方式去提供数据到机器中：一次性给完（batch)，一点一点的输入（online），让机器主动提出问题（active）

### 1) Batch

批量（batch）学习就是将很多数据一次性的给算法进行学习，是最常见的方式

### 2) Online

在线（online）学习就是一点一点将数据传输进去，如增强学习；

### 3) Active
主动（active）学习是主动提出问题让算法解决，可以节省大量的训练和标记消耗。类似于让机器提问题，告诉我们机器有什么问题不会，从而教它

--------------------------------
</br></br>

## 4. Learning with Different Input Space
不同的输入空间:具体特征（Concrete Features），原始特征（Raw Features），抽象特征（Abstract Features）

### 1) Concrete Features
具体特征（Concrete Features），具体特征最大特点就是便于机器学习的处理，这种情况是人类或者机器通过一定的方式提取获得的，具有实用性。

### 2) Raw Features
原始特征（Raw Features），如图片的像素等等，是最为常见到的资料，但是需要经过处理，转换成具体特征，才容易使用，实用性不太大。

### 3) Abstract Features
抽象特征（Abstract Features），如一些ID之类的看似无意义的数据，这就更需要特征的转换、提取等工作（相对于原始特征而言），几乎没有实用性。
